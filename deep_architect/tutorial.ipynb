{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An overview of DeepArchitect\n",
    "\n",
    "DeepArchitect is a framework for representing expressive search spaces over deep architectures and automatically search over them. We use an example workflow to present a step-by-step explanation of the main aspects of the framework. \n",
    "\n",
    "If you use this work, please cite: \n",
    "DeepArchitect: Automatically Designing and Training Deep Architectures (TODO: update with arXiv reference; temporary local version [here](http://www.cs.cmu.edu/~negrinho/assets/papers/deep_architect/deep_architect.pdf))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "\n",
    "We will be working with [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html). Run the two cells below to: download the dataset (only needs to be done once); load the training, validation, and test splits into memory, and set up standard data augmentation techniques. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "subprocess.call(['./download_cifar10.sh'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import darch.datasets as ds\n",
    "\n",
    "# options for data augmentation (random cropping, random flipping, zero padding)\n",
    "trans_height = 32\n",
    "trans_width = 32\n",
    "p_flip = 0.5\n",
    "pad_size = 4 \n",
    "in_d = (trans_height, trans_width, 3)\n",
    "nclasses = 10\n",
    "\n",
    "# load cifar-10.\n",
    "(Xtrain, ytrain, Xval, yval, Xtest, ytest) = ds.load_cifar10(\n",
    "        data_dir='data/cifar10/cifar-10-batches-py/', \n",
    "        flatten=False,\n",
    "        one_hot=True,\n",
    "        normalize_range=False,\n",
    "        whiten_pixels=True,\n",
    "        border_pad_size=pad_size)\n",
    "\n",
    "augment_train_fn = ds.get_augment_cifar_data_train(trans_height, trans_width, p_flip)\n",
    "augment_eval_fn = ds.get_augment_cifar_data_eval(trans_height, trans_width)\n",
    "\n",
    "# wrap data into a InMemoryDataset object.\n",
    "train_dataset = ds.InMemoryDataset(Xtrain, ytrain, True, augment_train_fn)\n",
    "val_dataset = ds.InMemoryDataset(Xval, yval, False, augment_eval_fn)\n",
    "test_dataset = ds.InMemoryDataset(Xtest, ytest, False, augment_eval_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a search space over models\n",
    "\n",
    "We propose an extensible and modular language that allows the human expert to compactly represent complex search spaces over architectures and their hyperparameters. \n",
    "\n",
    "We can construct a search space capturing many structural hyperparameters. In the complex search space example below, we choose whether to use batch normalization before or after relu, whether to use dropout or not, whether to use residual connections or not, and how many times to repeat each of the different modules. Besides these structural hyperparameters, there are also hyperparameters for the number of filters in the convolutional modules, the size of the filters, the dropout probability, and the scale of the initialization of the parameters.\n",
    "\n",
    "The code below exemplifies the usage of the **model search space specification language**. Other types of modules are available in darch/modules.py. We recommend you to take a look at the different modules there and think about what types of search spaces can be constructed using them. \n",
    "\n",
    "Run **one** of the cells below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A simple search space:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from darch.base import *\n",
    "from darch.modules import *\n",
    "from darch.initializers import *\n",
    "\n",
    "conv_initers = [ kaiming2015delving_initializer_conv(1.0) ]\n",
    "aff_initers = [ invsqrt_size_gaussian_initializer_affine( np.sqrt(2.0) )]\n",
    "\n",
    "b_search = Concat([\n",
    "                Conv2D([32, 48, 64, 96, 128], [1, 3, 5], [1], [\"SAME\"], conv_initers), \n",
    "                ReLU(),\n",
    "                MaxPooling2D([2], [2], [\"SAME\"]),\n",
    "                Conv2D([32, 48, 64, 96, 128], [1, 3, 5], [1], [\"SAME\"], conv_initers), \n",
    "                ReLU(),\n",
    "                MaxPooling2D([2], [2], [\"SAME\"]),\n",
    "                Affine([256, 512, 1024], aff_initers),\n",
    "                ReLU(),\n",
    "                Dropout([0.25, 0.5, 0.75]),\n",
    "                Affine([nclasses], aff_initers) \n",
    "           ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A complex search space:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from darch.base import *\n",
    "from darch.modules import *\n",
    "from darch.initializers import *\n",
    "\n",
    "# the initializers for the parameters (with different gains).\n",
    "gains = [0.1, 1.0]\n",
    "conv_initers = [ kaiming2015delving_initializer_conv( g ) for g in gains]\n",
    "aff_initers = [ xavier_initializer_affine( g ) for g in gains]\n",
    "\n",
    "# define some auxiliary modules (which represent some auxiliary spaces).\n",
    "def InnerModule_fn(filter_ns, filter_ls, keep_ps, stride=1):\n",
    "    return Concat([\n",
    "                Conv2D(filter_ns, filter_ls, [stride], [\"SAME\"], conv_initers),\n",
    "                MaybeSwap_fn( ReLU(), BatchNormalization() ),\n",
    "                Optional_fn( Dropout(keep_ps) )\n",
    "            ])\n",
    "\n",
    "def Module_fn(filter_ns, filter_ls, keep_ps, repeat_ns):\n",
    "    return RepeatTied(\n",
    "                Or([\n",
    "                    InnerModule_fn(filter_ns, filter_ls, keep_ps),\n",
    "                    Residual( InnerModule_fn(filter_ns, filter_ls, keep_ps) )\n",
    "                ]), \n",
    "            repeat_ns)\n",
    "\n",
    "# the composite search space.\n",
    "b_search = Concat([\n",
    "                InnerModule_fn([48, 64, 80, 96, 112, 128], [3, 5, 7], [0.5, 0.9], stride=2),\n",
    "                Module_fn([48, 64, 80, 96, 112, 128], [3, 5], [0.5, 0.9], [1, 2, 4, 8, 16, 32]),\n",
    "                InnerModule_fn([48, 64, 80, 96, 112, 128], [3, 5, 7], [0.5, 0.9], stride=2),\n",
    "                Module_fn([96, 128, 160, 192, 224, 256], [3, 5], [0.5, 0.9], [1, 2, 4, 8, 16, 32]),\n",
    "                Affine([nclasses], aff_initers)\n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating the searcher\n",
    "\n",
    "The definition of the search space only tells us the set of models that we will be considering, but it does not determine how the search space is going to be explored. This is the role of the **model search algorithm**.\n",
    "\n",
    "For this example, we will use a simple random searcher. Other model search algorithms are defined in darch/searchers.py. In our paper, we describe different model search algorithms and present experimental results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import darch.searchers as srch\n",
    "\n",
    "searcher = srch.RandomSearcher(b_search, in_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating the evaluator\n",
    "\n",
    "The **model evaluation algorithm** determines how each of the different models in the search space is going to be evaluated. \n",
    "\n",
    "This example uses a model evaluation algorithm that is specific to classification problems. Similar evaluators could be defined for other problems. Later in this notebook, we will look at an evaluator that has hyperparameters that will be searched jointly with the architecture of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import darch.evaluators as ev\n",
    "\n",
    "evaluator = ev.ClassifierEvaluator(train_dataset=train_dataset,\n",
    "                                   val_dataset=val_dataset,\n",
    "                                   in_d=in_d,\n",
    "                                   nclasses=nclasses,\n",
    "                                   training_epochs_max=int(1e6),\n",
    "                                   time_minutes_max=60, ###\n",
    "                                   display_step=1,\n",
    "                                   stop_patience=256, ###\n",
    "                                   rate_patience=8, ###\n",
    "                                   batch_patience=int(1e6),\n",
    "                                   save_patience=2, \n",
    "                                   rate_mult=0.66, ###\n",
    "                                   optimizer_type='adam', ###\n",
    "                                   learning_rate_init=2.5e-4, ###\n",
    "                                   learning_rate_min=1e-9, ###\n",
    "                                   batch_size_init=64,\n",
    "                                   model_path='out/model.ckpt',\n",
    "                                   output_to_terminal=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching the search space\n",
    "\n",
    "Now that we instantiated the **search space**, the **searcher**, and the **evaluator**, we can search over models. Let us use the searcher and evaluator to evaluate 3 models in the search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_models = 3\n",
    "\n",
    "# printing a textual representation for the search space.\n",
    "from pprint import pprint\n",
    "print \"*** Search space ***\"\n",
    "pprint( b_search.repr_program() , width=40, indent=2)\n",
    "print \n",
    "\n",
    "# running the searcher and evaluator.\n",
    "# prints a textual representation for the model sampled \n",
    "# from the space and logs the training process.\n",
    "print \"*** Models evaluated ***\"\n",
    "(scores, choice_hists) = srch.run_random_searcher(evaluator, \n",
    "                                                  searcher, \n",
    "                                                  num_models, \n",
    "                                                  output_to_terminal=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching over models and evaluation hyperparameters\n",
    "\n",
    "The hyperparameters of the previous evaluator (e.g., optimizer and learning rate schedule) were fixed. These hyperparameters can have a large impact on performance and often the human expert does not know good values apriori for them. In this example, we will see how can we jointly search over the model architectures and evaluation hyperparameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding the hyperparameters for the evaluation algorithm to the search space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b_hps = UserHyperparams(['optimizer_type',\n",
    "                         'learning_rate_init',\n",
    "                         'rate_mult',\n",
    "                         'rate_patience', \n",
    "                         'stop_patience', \n",
    "                         'learning_rate_min' ],\n",
    "                         [['adam', 'sgd_mom'], \n",
    "                         list( np.logspace(-2, -7, num=32) ), \n",
    "                         list( np.logspace(-2, np.log10(0.9), num=8) ),\n",
    "                         range(4, 33, 4), \n",
    "                         [64], \n",
    "                         [1e-9] ])\n",
    "\n",
    "# concatenating with the previously defined search space\n",
    "b_search_with_hps = Concat([b_hps, b_search])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining a custom evaluator that extracts the values for the evaluator hyperparameters, instantiates the evaluator, and evaluates the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import darch.evaluators as ev\n",
    "\n",
    "# NOTE that this evaluator relies on the specific structure of the search space\n",
    "# to extract the values of the hyperparameters.\n",
    "class CustomEvaluator:\n",
    "    \"\"\"Custom evaluator whose performance depends on the values of certain\n",
    "    hyperparameters specified in the hyperparameter module. Hyperparameters that \n",
    "    we do not expect to set this way, will take default values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_dataset, val_dataset, test_dataset, in_d, nclasses, \n",
    "            max_minutes_per_model, model_path, output_to_terminal):\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        self.in_d = in_d\n",
    "        self.nclasses = nclasses\n",
    "        self.max_minutes_per_model = max_minutes_per_model\n",
    "        self.model_path = model_path\n",
    "        self.output_to_terminal = output_to_terminal\n",
    "        \n",
    "    def eval_model(self, b):\n",
    "        \"\"\"Extract parameters from a UserHyperparams module and uses then to \n",
    "        udpate the values of certain hyperparameters of the evaluator. This \n",
    "        code is still very much based on ClassifierEvaluator.\n",
    "        \"\"\"\n",
    "        \n",
    "        # extraction of the evaluator hyperparameters (NOTE: slight violation of encapsulation).\n",
    "        b_hp, b_search = b.bs\n",
    "        b_hp.compile(None, None, None)\n",
    "        order = b_hp.scope.s['UserHyperparams-0']['hyperp_names']\n",
    "        vals = b_hp.scope.s['UserHyperparams-0']['hyperp_vals']\n",
    "        hps = dict(zip(order, vals))\n",
    "\n",
    "        evaluator = ev.ClassifierEvaluator(train_dataset=self.train_dataset,\n",
    "                                        val_dataset=self.val_dataset,\n",
    "                                        test_dataset=self.test_dataset,\n",
    "                                        in_d=self.in_d,\n",
    "                                        nclasses=self.nclasses,\n",
    "                                        training_epochs_max=int(1e6),\n",
    "                                        time_minutes_max=self.max_minutes_per_model,\n",
    "                                        display_step=1,\n",
    "                                        stop_patience=hps['stop_patience'], ###\n",
    "                                        rate_patience=hps['rate_patience'], ###\n",
    "                                        batch_patience=int(1e6),\n",
    "                                        save_patience=2, \n",
    "                                        rate_mult=hps['rate_mult'], ###\n",
    "                                        optimizer_type=hps['optimizer_type'], ###\n",
    "                                        learning_rate_init=hps['learning_rate_init'], ###\n",
    "                                        learning_rate_min=hps['learning_rate_min'], ###\n",
    "                                        batch_size_init=64,\n",
    "                                        model_path=self.model_path,\n",
    "                                        output_to_terminal=self.output_to_terminal)\n",
    "        return evaluator.eval_model(b_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Searching the search space is done the same way once the evaluator is defined**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ctm_num_models = 3\n",
    "\n",
    "import darch.searchers as srch\n",
    "\n",
    "# instantiate the evaluator.\n",
    "ctm_evaluator = CustomEvaluator(train_dataset=train_dataset,\n",
    "                                val_dataset=val_dataset,\n",
    "                                test_dataset=None,\n",
    "                                in_d=in_d,\n",
    "                                nclasses=nclasses,\n",
    "                                max_minutes_per_model=60, ###\n",
    "                                model_path='out/model_custom.ckpt',\n",
    "                                output_to_terminal=True)\n",
    "\n",
    "# instantiate the searcher.\n",
    "ctm_searcher = srch.RandomSearcher(b_search_with_hps, in_d)\n",
    "\n",
    "# printing a textual representation for the search space.\n",
    "from pprint import pprint\n",
    "print \"*** Search space ***\"\n",
    "pprint( b_search_with_hps.repr_program() , width=40, indent=2)\n",
    "print \n",
    "\n",
    "# using the searcher and evaluator to explore the space.\n",
    "print \"*** Models evaluated ***\"\n",
    "(ctm_scores, ctm_choice_hists) = srch.run_random_searcher(ctm_evaluator, \n",
    "                                                          ctm_searcher, \n",
    "                                                          ctm_num_models, \n",
    "                                                          output_to_terminal=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "In this tutorial we have seem how DeepArchitect allows to easily set up a search space over models and automatically search and evaluate them. The three fundamental components of the framework are the **model search space specification language**, the **model search algorithm**, and the **model evaluation algorithm**. Any of these components can be modified or extended while keeping the others fixed.\n",
    "\n",
    "To explore the code further, we suggest the following: \n",
    "* Understand the module interface, e.g., look at `BasicModule` in darch/module.py.\n",
    "* Understand how the module interface is used by the searcher to transverse the search space, e.g., look `RandomSearcher` in darch/searchers.py.\n",
    "* Understand how an evaluator uses the module interface to compile a fully specified model to a computational graph and evaluate it, e.g., look at `ClassifierEvaluator` in darch/evaluators.py.\n",
    "* Implement new modules capturing interesting structural transformations that you want to define. Look at some  instructive implementations such as `BasicModule`, `Affine`, `Conv2D`, `Or`, `Repeat`, and `Residual`.\n",
    "* Implement new modules with complex wiring structure (but perhaps still single-input single-output). `Residual` is an instructive example to look at.\n",
    "* Implement new evaluators for tasks of interest, e.g., reinforcement learning.\n",
    "\n",
    "The extension of DeepArchitect to multiple-input multiple-output modules can be done along the same lines of the single-input single-output. The main differences are that the search space needs to be traversed slightly differently and compilation requires slightly more bookkeeping. Nonetheless, the same module interface is valid and the insights described in the paper carry over unchanged or slightly adapted. \n",
    "\n",
    "In the near future, we intend to implement the multiple-input multiple-output extension and provide support for PyTorch. \n",
    "\n",
    "If you use or extend DeepArchitect, cite:\n",
    "DeepArchitect: Automatically Designing and Training Deep Architectures (TODO: update with arXiv reference)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Want to contribute or have ideas?\n",
    "\n",
    "Reach out to negrinho at cs dot cmu dot .\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
